# -*- coding: utf-8 -*-
"""SVMML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u80a6yF3B6c9fivUKgKCWw7fcsd2ClPz
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %ls -l
# %cd 'drive/'

# Commented out IPython magic to ensure Python compatibility.
# %ls -l
# %cd 'MyDrive/'

import pandas as pd

file_path = "/content/drive/MyDrive/Phishing_Legitimate_full.csv"
df = pd.read_csv(file_path)

# Step 1: Install required packages (if not already installed)
!pip install pandas scikit-learn numpy matplotlib

# Step 2: Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_classif
import matplotlib.pyplot as plt
import seaborn as sns

# Step 3: Load the dataset (Data is already loaded in a previous cell)
# from io import StringIO
# file_content = """[your entire CSV file content here]"""
# # Remove the first and last lines that aren't part of the CSV
# csv_content = '\n'.join(file_content.split('\n')[1:-1])
# df = pd.read_csv(StringIO(csv_content))

# Step 4: Data Exploration
print("Dataset shape:", df.shape)
print("\nFirst 5 rows:")
print(df.head())
print("\nClass distribution:")
print(df['CLASS_LABEL'].value_counts())

# Step 5: Data Preprocessing
# Separate features and target
X = df.drop(['id', 'CLASS_LABEL'], axis=1)
y = df['CLASS_LABEL']

# Handle missing values if any (this dataset appears clean)
print("\nMissing values per column:")
print(X.isnull().sum())

# Identify and remove constant features
constant_features = X.columns[X.nunique() == 1]
print(f"\nConstant features to be removed: {list(constant_features)}")
X = X.drop(columns=constant_features)

# Feature scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Optional: Feature selection
selector = SelectKBest(f_classif, k=30)  # Select top 30 features
X_selected = selector.fit_transform(X_scaled, y)

# Get selected feature names
selected_features = X.columns[selector.get_support()]
print("\nSelected features:")
print(selected_features)

# Step 6: Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y, test_size=0.3, random_state=42, stratify=y
)

# Step 7: Train the SVM model
svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)
svm_model.fit(X_train, y_train)

# Step 8: Model Evaluation
y_pred = svm_model.predict(X_test)

print("\nModel Evaluation:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
              xticklabels=['Legitimate', 'Phishing'],
              yticklabels=['Legitimate', 'Phishing'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Step 9: Feature Importance Analysis (for linear kernel)
# For non-linear kernels, we can use permutation importance
from sklearn.inspection import permutation_importance

result = permutation_importance(svm_model, X_test, y_test, n_repeats=10, random_state=42)
sorted_idx = result.importances_mean.argsort()

plt.figure(figsize=(12, 8))
plt.boxplot(result.importances[sorted_idx].T,
              vert=False, labels=selected_features[sorted_idx])
plt.title("Permutation Importance (test set)")
plt.tight_layout()
plt.show()

# Step 10: Save the model (optional)
import joblib
joblib.dump(svm_model, 'phishing_detection_svm.pkl')
joblib.dump(scaler, 'scaler.pkl')
joblib.dump(selector, 'feature_selector.pkl')

print("\nModel saved to phishing_detection_svm.pkl")

# ===== 1. DEPENDENCY SETUP =====
print("Setting up environment...")
!pip install --quiet --upgrade pip
!pip install --quiet "numpy>=1.21.0" "scikit-learn>=1.0.0" "pandas>=1.3.0" "matplotlib>=3.5.0"
!pip install --quiet "qiskit>=1.0.0" "qiskit-aer>=0.13.0" "qiskit-machine-learning>=0.7.0"
!pip install --quiet seaborn

# ===== 2. IMPORT LIBRARIES =====
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.svm import SVC

# Quantum imports - updated for current Qiskit versions
from qiskit import QuantumCircuit
from qiskit.circuit.library import ZZFeatureMap
from qiskit_machine_learning.kernels import FidelityQuantumKernel
from qiskit_machine_learning.algorithms import QSVC
from qiskit_aer import Aer
from qiskit.primitives import Sampler
import random  # We'll use Python's random instead of algorithm_globals

# ===== 3. UTILITY FUNCTIONS =====
def plot_qsvm_confusion_matrix(y_true, y_pred, title='Quantum SVM Confusion Matrix'):
    """
    Enhanced confusion matrix visualization for QSVM results with quantum styling
    """
    cm = confusion_matrix(y_true, y_pred)

    plt.figure(figsize=(8, 6))
    sns.set(style="white", font_scale=1.2)
    ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Purples',
                    annot_kws={"size": 16, "color": 'black'},
                    xticklabels=['Predicted -1', 'Predicted +1'],
                    yticklabels=['Actual -1', 'Actual +1'],
                    cbar_kws={'label': 'Quantum State Counts'})

    plt.xlabel('Quantum Prediction', fontsize=14, labelpad=15)
    plt.ylabel('True State', fontsize=14, labelpad=15)
    plt.title(title, fontsize=16, pad=20)

    # Quantum styling
    for spine in ax.spines.values():
        spine.set_edgecolor('purple')
        spine.set_linewidth(2)

    plt.tight_layout()
    plt.show()

def evaluate_model(y_true, y_pred, model_name="QSVM"):
    """Comprehensive evaluation of quantum model performance"""
    print(f"\n{model_name} Performance Evaluation")
    print("="*40)
    print(f"Accuracy: {accuracy_score(y_true, y_pred):.2%}")
    print("\nClassification Report:")
    print(classification_report(y_true, y_pred, target_names=['Class -1', 'Class +1']))

    # Plot confusion matrix
    plot_qsvm_confusion_matrix(y_true, y_pred, f'{model_name} Confusion Matrix')

# ===== 4. DEMONSTRATION WITH DUMMY DATA =====
def run_demo():
    """Demonstrate QSVM evaluation with synthetic data"""
    print("\nRunning Quantum SVM Demonstration...")
    random.seed(12345)  # Using Python's random instead of algorithm_globals
    np.random.seed(12345)

    # Create synthetic quantum-like data
    n_samples = 100
    X = np.random.rand(n_samples, 2)
    y = np.where(X[:, 0] + X[:, 1] > 1, 1, -1)  # Simple decision boundary

    # Add some noise to make it more realistic
    y = np.where(np.random.random(n_samples) < 0.1, -y, y)

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Quantum setup - using correct Aer import
    backend = Aer.get_backend('statevector_simulator')
    sampler = Sampler()  # Using the new Sampler primitive

    # Create quantum feature map
    feature_map = ZZFeatureMap(feature_dimension=2, reps=2)

    # Quantum kernel - updated for Qiskit 1.0+
    quantum_kernel = FidelityQuantumKernel(feature_map=feature_map, sampler=sampler)

    # Quantum SVM
    qsvm = QSVC(quantum_kernel=quantum_kernel)

    # Train and predict
    print("\nTraining Quantum SVM...")
    qsvm.fit(X_train, y_train)
    y_pred = qsvm.predict(X_test)

    # Evaluate
    evaluate_model(y_test, y_pred, "Quantum SVM")

    # Compare with classical SVM
    print("\nTraining Classical SVM for comparison...")
    classical_svm = SVC(kernel='rbf')
    classical_svm.fit(X_train, y_train)
    y_pred_classical = classical_svm.predict(X_test)

    evaluate_model(y_test, y_pred_classical, "Classical RBF SVM")

# ===== 5. MAIN EXECUTION =====
if __name__ == "__main__":
    try:
        # Check if QSVM results already exist in environment
        if 'y_test' in globals() and 'y_pred_qsvm' in globals():
            print("\nFound existing QSVM results. Evaluating...")
            evaluate_model(y_test, y_pred_qsvm)
        else:
            print("\nNo existing QSVM results found. Running demonstration...")
            run_demo()
    except Exception as e:
        print(f"\nError encountered: {str(e)}")
        print("Falling back to dummy data evaluation...")
        np.random.seed(42)
        y_test_dummy = np.random.choice([-1, 1], size=100)
        y_pred_dummy = np.random.choice([-1, 1], size=100)
        evaluate_model(y_test_dummy, y_pred_dummy, "Dummy Data Example")